# Basics (Scratch)

This folder will be focused on coding various components of neural net architectures from scratch. This inclues:

- Forward passes through layers/activations/losses/etc
- Backward passes through layers/activations/losses/etc by backpropagation
- Moving models to a device
- Optimization step

As opposed to "Basics (PyTorch)", I will also try to implement the backward steps, rather than relying on autograd.

# Directory structure

## Activations

- ReLu

To add:
- Sigmoid


## Layers

- Linear layer

To add:
- Convolution

## Losses

- L2 loss

To add:
- Logistic loss

## Models

- Basic model of sequential layers

## Module

- Holds my rudimentary version of the PyTorch "Module" class
